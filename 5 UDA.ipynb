{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import random_split, DataLoader, Dataset\n",
    "\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"nreimers/MiniLM-L6-H384-uncased\" # Session 11 to know about MiniLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load tokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "\n",
    "ag_news = load_dataset(\"ag_news\")['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ag_news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data\n",
    "\n",
    "supervised, unsupervised, val = random_split(ag_news, [10000, 100000, 10000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a Tfidf augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # adapted from https://github.com/makcedward/nlpaug/blob/master/example/tfidf-train_model.ipynb\n",
    "\n",
    "import re\n",
    "# pip install numpy requests nlpaug\n",
    "import nltk\n",
    "import nlpaug.augmenter.word as naw \n",
    "import nlpaug.model.word_stats as nmw\n",
    "\n",
    "# def _tokenizer(text, token_pattern=r\"(?u)\\b\\w\\w+\\b\"):\n",
    "#     token_pattern = re.compile(token_pattern)\n",
    "#     return token_pattern.findall(text)\n",
    "\n",
    "# # Tokenize input\n",
    "# train_x_tokens = [_tokenizer(x['text'].lower()) for x in ag_news]\n",
    "\n",
    "# # Train TF-IDF model\n",
    "# tfidf_model = nmw.TfIdf()\n",
    "# tfidf_model.train(train_x_tokens)\n",
    "# tfidf_model.save('.')\n",
    "\n",
    "# # Load TF-IDF augmenter\n",
    "# tf_idf_aug = naw.TfIdfAug(model_path='.', tokenizer=_tokenizer, stopwords=nltk.corpus.stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf_idf_aug.augment('my computer is broken')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del_aug = naw.random.RandomWordAug(action='delete')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UdaData(Dataset):\n",
    "    \n",
    "    def __init__(self, data, supervised = True):\n",
    "        \n",
    "        self.data = data\n",
    "        \n",
    "        self.supervised = supervised\n",
    "        \n",
    "    def __len__(self): return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        x, y = self.data[idx]['text'], self.data[idx]['label']\n",
    "        \n",
    "        if self.supervised:\n",
    "            \n",
    "            return x, y\n",
    "        \n",
    "        else:\n",
    "            \n",
    "            return x, del_aug.augment(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_encode(texts, max_length):\n",
    "    \n",
    "    return tokenizer.batch_encode_plus(texts, # ['text 1', 'text 2', ...]\n",
    "                                       return_tensors='pt',\n",
    "                                       padding=True,\n",
    "                                       truncation=True,\n",
    "                                       max_length=max_length,\n",
    "                                       return_token_type_ids=False,\n",
    "                                       return_attention_mask=False)['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_sup(batch, max_length=100):\n",
    "    \n",
    "    texts = [b[0] for b in batch]\n",
    "    \n",
    "    y = torch.LongTensor([b[1] for b in batch])\n",
    "    \n",
    "    x = batch_encode(texts, max_length)\n",
    "    \n",
    "    return [x, y]\n",
    "\n",
    "def collate_unsup(batch, max_length=100):\n",
    "    \n",
    "    texts_1 = [b[0] for b in batch]\n",
    "    \n",
    "    texts_2 = [b[1] for b in batch]\n",
    "    \n",
    "    x_1 = batch_encode(texts_1, max_length)\n",
    "    \n",
    "    x_2 = batch_encode(texts_2, max_length)\n",
    "    \n",
    "    return [x_1, x_2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sup_batch_size = 128\n",
    "mu = 2\n",
    "\n",
    "sup_loader = DataLoader(UdaData(supervised, supervised=True), batch_size=sup_batch_size, shuffle=True, collate_fn=collate_sup, num_workers=15)\n",
    "\n",
    "unsup_loader = DataLoader(UdaData(unsupervised, supervised=False), batch_size=sup_batch_size * mu, shuffle=True, collate_fn=collate_unsup, num_workers=15)\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(UdaData(val, supervised=True), batch_size=100, shuffle=False, collate_fn=collate_sup, num_workers=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x1, y in sup_loader:\n",
    "    print(x)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "def delete_some_layers(model):\n",
    "        \n",
    "    oldModuleList = model.encoder.layer\n",
    "    \n",
    "    newModuleList = nn.ModuleList()\n",
    "    \n",
    "    # just keep encoder layers [0, 2, 4]\n",
    "    for i in range(0, 6, 2):\n",
    "        newModuleList.append(oldModuleList[i])\n",
    "\n",
    "    copyOfModel = copy.deepcopy(model)\n",
    "    copyOfModel.encoder.layer = newModuleList\n",
    "\n",
    "    return copyOfModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MinilmClassifier(nn.Module):\n",
    "    \n",
    "    def __init__(self, num_classes, num_layers=2):\n",
    "        super().__init__()\n",
    "        \n",
    "        minilm = AutoModel.from_pretrained(MODEL_NAME)\n",
    "        \n",
    "        self.encoder = delete_some_layers(minilm)\n",
    "        \n",
    "        hidden_size = self.encoder.config.hidden_size\n",
    "        \n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(hidden_size, num_classes),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        attention_mask = (x != 0)\n",
    "        \n",
    "        pooled = self.encoder(input_ids=x, attention_mask=attention_mask)['pooler_output']\n",
    "        \n",
    "        return self.fc(pooled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MinilmClassifier(num_classes=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model(x).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_uda(model: nn.Module,\n",
    "                    opt: torch.optim,\n",
    "                    sup_loader: torch.utils.data.DataLoader,\n",
    "                    unsup_loader: torch.utils.data.DataLoader,\n",
    "                    alpha: float=0.5):\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for param in model.parameters():\n",
    "        device = param.device\n",
    "        break\n",
    "    \n",
    "    losses = []\n",
    "    \n",
    "    pbar = tqdm(sup_loader)\n",
    "    \n",
    "    unsup_iter = iter(unsup_loader)\n",
    "    \n",
    "    for batch_sup in pbar:\n",
    "        \n",
    "        model.zero_grad()\n",
    "        \n",
    "        # labelled data\n",
    "        x_1, y = batch_sup\n",
    "        x_1, y = x_1.to(device), y.to(device)\n",
    "        \n",
    "        # supervised cross-entropy loss\n",
    "        logits_sup = model(x_1)\n",
    "        loss_sup = F.cross_entropy(logits_sup, y)\n",
    "        \n",
    "        # unlabelled data\n",
    "        try:\n",
    "            x_2, x_aug = next(unsup_iter)\n",
    "        except StopIteration:\n",
    "            unsup_iter = iter(unsup_loader)\n",
    "            x_2, x_aug = next(unsup_iter)\n",
    "                \n",
    "        x_2, x_aug = x_2.to(device), x_aug.to(device)\n",
    "        \n",
    "        # prediction for the non-augmented data\n",
    "        with torch.no_grad():\n",
    "            logits_x_2 = model(x_2)\n",
    "        \n",
    "        # prediction for the augmented data\n",
    "        logits_x_aug = model(x_aug)\n",
    "        \n",
    "        # cross-entropy between the non-augmented and augmented\n",
    "        loss_unsup = F.kl_div(F.log_softmax(logits_x_aug, dim=1), F.softmax(logits_x_2, dim=1), reduction='none').sum(1)\n",
    "        \n",
    "        # sum losses\n",
    "        loss = loss_sup + alpha * loss_unsup.mean()\n",
    "        \n",
    "        loss.backward()\n",
    "\n",
    "        opt.step()\n",
    "        \n",
    "        loss_item = loss.item()\n",
    "        \n",
    "        losses.append(loss_item)\n",
    "        \n",
    "        pbar.set_description(f'train_loss = {np.array(losses).mean(): .3f}')\n",
    "        \n",
    "    return np.array(losses).mean()\n",
    "\n",
    "@torch.no_grad()\n",
    "def validate(model: nn.Module, dataloader: torch.utils.data.DataLoader):\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    for param in model.parameters():\n",
    "        device = param.device\n",
    "        break\n",
    "     \n",
    "    labels_all = []\n",
    "    logits_all = []\n",
    "    \n",
    "    for x, y in dataloader:\n",
    "\n",
    "        x, y = x.to(device), y.to(device)\n",
    "\n",
    "        logits = model(x)\n",
    "        \n",
    "        labels_all += y.cpu().numpy().tolist()\n",
    "        logits_all += logits.cpu().numpy().tolist()\n",
    "        \n",
    "    prediction = np.argmax(np.array(logits_all), axis=-1)\n",
    "    \n",
    "    acc = accuracy_score(labels_all, prediction)\n",
    "                    \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize model\n",
    "\n",
    "model = MinilmClassifier(num_classes=4).cuda()\n",
    "\n",
    "opt = torch.optim.AdamW(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in range(5):\n",
    "    train_uda(model, opt, sup_loader, unsup_loader, alpha=1.)\n",
    "    val_acc = validate(model, val_loader)\n",
    "    print(val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37_UZA",
   "language": "python",
   "name": "py37_uza"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "10c013a2ccba4ec88874799ff17e9bee": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "2c0ddb6deccd45ef9754aa7d50a0252b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "322382cf7ba64e17baabfb38652409b3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_4161e5d796cd4309827c8e819ea08894",
        "IPY_MODEL_40de65a267ef419ca5bc6945ac69f615",
        "IPY_MODEL_6658879ff97e49d6bf389bf7ea93a75b"
       ],
       "layout": "IPY_MODEL_89dbdd94d848460c8de29c9d53e483d5"
      }
     },
     "3ff3c53c2f2745848a438020e5e651b6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "40de65a267ef419ca5bc6945ac69f615": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_4d5b3fb113e04fde8a3a884a209986d4",
       "max": 79,
       "style": "IPY_MODEL_989afb0e2cc140ae8510a32a346c03b1",
       "value": 79
      }
     },
     "4161e5d796cd4309827c8e819ea08894": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_10c013a2ccba4ec88874799ff17e9bee",
       "style": "IPY_MODEL_7e210290259347998c5824d7e5d78341",
       "value": "train_loss =  0.536: 100%"
      }
     },
     "4d5b3fb113e04fde8a3a884a209986d4": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "53ba3064e4ea448bb27668a50cc28538": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "6658879ff97e49d6bf389bf7ea93a75b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_7c3bb80172e64aeaa9c873d5e5e87f29",
       "style": "IPY_MODEL_bddb81c95f86497d9a2bf458265befb0",
       "value": " 79/79 [00:28&lt;00:00,  2.58it/s]"
      }
     },
     "6ed9ced3c1b14585bcf516003b2facdc": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "764faa3b69074ab7afe59725c8aa81b6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_a5be1ba641f64be0824a2389a9895341",
        "IPY_MODEL_bfbf057125014397835a6e759ddad603",
        "IPY_MODEL_bfe378ec69e54e069078a70d9f85e6f6"
       ],
       "layout": "IPY_MODEL_2c0ddb6deccd45ef9754aa7d50a0252b"
      }
     },
     "7c3bb80172e64aeaa9c873d5e5e87f29": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "7e210290259347998c5824d7e5d78341": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "89dbdd94d848460c8de29c9d53e483d5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "989afb0e2cc140ae8510a32a346c03b1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "a3658fc599024b1dadf6c77d5c921c38": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "a5be1ba641f64be0824a2389a9895341": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_e1ef1ca7af76471fb3b205a916a235cf",
       "style": "IPY_MODEL_d2811da0b709483aae49c1b2784be74d",
       "value": "train_loss =  0.257:  23%"
      }
     },
     "bddb81c95f86497d9a2bf458265befb0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "bfbf057125014397835a6e759ddad603": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "danger",
       "layout": "IPY_MODEL_6ed9ced3c1b14585bcf516003b2facdc",
       "max": 79,
       "style": "IPY_MODEL_a3658fc599024b1dadf6c77d5c921c38",
       "value": 18
      }
     },
     "bfe378ec69e54e069078a70d9f85e6f6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_3ff3c53c2f2745848a438020e5e651b6",
       "style": "IPY_MODEL_53ba3064e4ea448bb27668a50cc28538",
       "value": " 18/79 [00:20&lt;01:10,  1.16s/it]"
      }
     },
     "d2811da0b709483aae49c1b2784be74d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "e1ef1ca7af76471fb3b205a916a235cf": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
