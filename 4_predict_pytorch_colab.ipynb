{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hydrometeorological-Remote-Sensing/cropmapping/blob/sw_ww_test/predict_pytorch_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NTJugWlEwi5G"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qK9GT5uOsywv"
      },
      "outputs": [],
      "source": [
        "!pip install -q segmentation_models_pytorch \n",
        "!pip install -q affine\n",
        "!pip install -q rioxarray "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eVbsu2H8WV-x"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount(\"/content/drive\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QwJkxmD7Yqjm"
      },
      "outputs": [],
      "source": [
        "!cp /content/drive/MyDrive/RDA/model_and_env/data_loader.py data_loader.py\n",
        "!cp /content/drive/MyDrive/RDA/model_and_env/unet_pytorch.py unet_pytorch.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K4g9drohTRZa"
      },
      "outputs": [],
      "source": [
        "import datetime\n",
        "import segmentation_models_pytorch as smp\n",
        "import numpy as np\n",
        "import torch\n",
        "from glob import glob\n",
        "import torch.utils.data\n",
        "from data_loader import data_load\n",
        "import tensorflow as tf\n",
        "from unet_pytorch import build_unet\n",
        "import torch.nn as nn\n",
        "import json\n",
        "import xarray as xr\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from copy import deepcopy\n",
        "import pandas as pd\n",
        "from affine import Affine\n",
        "from scipy.sparse import *\n",
        "import rioxarray"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cIcVdSewqlY2"
      },
      "outputs": [],
      "source": [
        "def to_image(img, mixer, raster_dir):\n",
        "    f = open(*mixer)\n",
        "    mixer = json.load(f)\n",
        "    f.close()\n",
        "    doubleMatrix = mixer[\"projection\"][\"affine\"][\"doubleMatrix\"]\n",
        "    patchesPerRow = mixer[\"totalPatches\"] / mixer[\"patchesPerRow\"]\n",
        "    img = np.split(img, patchesPerRow)\n",
        "    img = [np.hstack(l) for l in img]\n",
        "    img = np.vstack(img).astype(\"int8\")\n",
        "    ds = xr.DataArray(img)\n",
        "    img = []\n",
        "    ds = ds.rio.write_crs(4326, inplace=True)\n",
        "    transform = Affine(*doubleMatrix)\n",
        "    ds.rio.write_transform(transform, inplace=True)\n",
        "    ds.spatial_ref.GeoTransform\n",
        "    ds.rio.set_spatial_dims(\"dim_1\", \"dim_0\")\n",
        "    ds.rio.to_raster(raster_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yPqA4kBybeBx"
      },
      "outputs": [],
      "source": [
        "!mkdir npyfiles"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8BFNg7zukHJv"
      },
      "outputs": [],
      "source": [
        "# from state_dict import *\n",
        "def doPrediction(tf_files, model):\n",
        "    print(tf_files)\n",
        "    file_ls = np.append(\n",
        "        np.arange(0, 70) * int(len(list(tf_files)) / 70), len(list(tf_files))\n",
        "    )\n",
        "    patches = 0\n",
        "    np_ls = []\n",
        "    _ = 1\n",
        "    for i in range(len(file_ls) - 1):\n",
        "        print(i)\n",
        "        data = data_load(\n",
        "            tf_files[file_ls[i] : file_ls[i + 1]],\n",
        "            bands,\n",
        "            description,\n",
        "            batch_size=batch_size,\n",
        "        ).get_pridiction_dataset()\n",
        "        ls = []\n",
        "        for batch in data.as_numpy_iterator():\n",
        "            # print(batch.shape)\n",
        "            predictions = torch.tensor(batch).to(device)\n",
        "            with torch.no_grad():\n",
        "                predictions = model(predictions).cpu().numpy()  # .tolist()\n",
        "            # print(predictions.shape)\n",
        "            predictions = predictions.argmax(axis=1).squeeze()[\n",
        "                :,\n",
        "                x_buffer : x_buffer + kernel_shape[0],\n",
        "                y_buffer : y_buffer + kernel_shape[1],\n",
        "            ]\n",
        "            print(\"Writing patch \" + str(_ * 64) + \"...\", flush=True)\n",
        "            _ = _ + 1\n",
        "            ls.append(predictions)\n",
        "        np_ls.append(np.vstack(ls).astype(\"int8\"))\n",
        "    return np_ls\n",
        "    print(\"finished\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IuxlpG3VngBk"
      },
      "outputs": [],
      "source": [
        "ckpt_path = \"/content/drive/MyDrive/RDA/model_and_env/sw_ww_test/ww_56_model/checkpoint.pt\"\n",
        "\n",
        "bands = [\n",
        "    \"blue\",\n",
        "    \"green\",\n",
        "    \"red\",\n",
        "    \"nir\",\n",
        "    \"swir1\",\n",
        "    \"swir2\",\n",
        "    \"ndvi\",\n",
        "    \"nirv\"\n",
        "]\n",
        "targets = [\"cropland\"]\n",
        "features = bands  # + targets\n",
        "nclass = 2\n",
        "batch_size = 32\n",
        "class_names = [\"Others\", \"Wheat\"]\n",
        "kernel_shape = [256, 256]\n",
        "kernel_buffer = [128, 128]\n",
        "# Get set up for prediction.\n",
        "x_buffer = int(kernel_buffer[0] / 2)\n",
        "y_buffer = int(kernel_buffer[1] / 2)\n",
        "\n",
        "buffered_shape = [\n",
        "    kernel_shape[0] + kernel_buffer[0],\n",
        "    kernel_shape[1] + kernel_buffer[1],\n",
        "]\n",
        "columns = [\n",
        "    tf.io.FixedLenFeature(shape=buffered_shape, dtype=tf.float32) for k in features\n",
        "]\n",
        "description = dict(zip(features, columns))\n",
        "metrics_dict = {}\n",
        "device = \"cuda\"\n",
        "folder = \"prediction\"\n",
        "model = (\n",
        "    build_unet(len(bands), nclass).cuda()\n",
        "    if device == \"cuda\"\n",
        "    else build_unet(len(bands), nclass)\n",
        ")\n",
        "model = nn.DataParallel(model)\n",
        "model.load_state_dict(torch.load(ckpt_path))\n",
        "model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tzMZSBW2-ZSp"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yzy5qhiLtbmA"
      },
      "outputs": [],
      "source": [
        "states = ['North Dakota'] \n",
        "for state in states:\n",
        "    print(\"predicting \", state)\n",
        "    folder = (\n",
        "        \"/content/drive/MyDrive/RDA/prediciton/prediction_sw_67_{}\".format(\n",
        "            state\n",
        "        )\n",
        "    )\n",
        "    tf_files = glob(folder + \"/*.gz\")\n",
        "    tf_files.sort()\n",
        "    json_file = glob(folder + \"/*.json\")\n",
        "    out_image_file = \"/content/drive/MyDrive/RDA/geotiff_result/{}_pytorch.tif\".format(\n",
        "        state\n",
        "    )\n",
        "    prediction = doPrediction(tf_files, model)\n",
        "    # tifname = state\n",
        "    # files = sorted(glob(f\"npyfiles/*.npy\"), key=os.path.getmtime)\n",
        "    img = np.vstack(prediction)\n",
        "    np.save(\"/content/drive/MyDrive/RDA/geotiff_result/{}.npy\".format(state), img)\n",
        "    to_image(img, json_file, out_image_file)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "include_colab_link": true,
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.10"
    },
    "vscode": {
      "interpreter": {
        "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
