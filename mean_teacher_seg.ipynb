{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-15 22:36:43.461566: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-15 22:36:43.758656: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-02-15 22:36:45.261973: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-15 22:36:45.262101: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-15 22:36:45.262109: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from data_loader import data_load\n",
    "from unet_pytorch import build_unet\n",
    "from ramps import get_current_consistency_weight, update_ema_variables\n",
    "from glob import glob\n",
    "import tensorflow as tf\n",
    "from time import time\n",
    "from monai.losses import DiceLoss\n",
    "from monai.metrics import DiceMetric\n",
    "from monai.transforms import (\n",
    "    Compose,\n",
    "    AsDiscrete,\n",
    "    EnsureType,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "BANDS = [\"blue\", \"green\", \"red\", \"nir\", \"swir1\", \"swir2\", \"ndvi\", \"nirv\"]\n",
    "KERNEL_SHAPE = [256, 256]\n",
    "KERNEL_BUFFER = [128, 128]\n",
    "X_BUFFER, Y_BUFFER = [buffer // 2 for buffer in KERNEL_BUFFER]\n",
    "BUFFERED_SHAPE = [kernel + buffer for kernel, buffer in zip(KERNEL_SHAPE, KERNEL_BUFFER)]\n",
    "TARGETS = [\"cropland\"]\n",
    "MASK = (slice(None), (X_BUFFER, X_BUFFER + KERNEL_SHAPE[0]), (Y_BUFFER, Y_BUFFER + KERNEL_SHAPE[1]))\n",
    "NCLASS = 2\n",
    "\n",
    "\n",
    "def load_dataset(batch, folder, label=True, buffer_size=6000):\n",
    "    features = BANDS + TARGETS if label else BANDS\n",
    "    sub_folder = \"labeled\" if label else \"unlabeled\"\n",
    "    tf_files = glob(f\"{folder}/{sub_folder}/*.gz\")\n",
    "    columns = [tf.io.FixedLenFeature(shape=KERNEL_SHAPE, dtype=tf.float32) for _feature in features]\n",
    "    description = dict(zip(features, columns))\n",
    "    data_func = data_load(tf_files, BANDS, description, response=TARGETS, batch_size=batch, buffer_size=buffer_size)\n",
    "    data = data_func.get_training_dataset() if label else data_func.get_pridiction_dataset()\n",
    "    # print(tf_files)\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(32,'/bess23/huaize/semi-supervised/data/labeled',label=True)\n",
    "test_dataset = load_dataset(32,'/bess23/huaize/semi-supervised/data/unlabeled',label=False)\n",
    "train_loader = dataset.as_numpy_iterator()\n",
    "unlabeled_train_loader = test_dataset.as_numpy_iterator()\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "model = build_unet(len(BANDS),NCLASS).cuda()\n",
    "ema_model = build_unet(len(BANDS),NCLASS).cuda()\n",
    "model = nn.DataParallel(model) \n",
    "ema_model = nn.DataParallel(ema_model)\n",
    "model.to(device)\n",
    "ema_model.to(device)\n",
    "max_epochs = 1000\n",
    "MeanTeacherEpoch = 50\n",
    "\n",
    "lr= 1e-4\n",
    "opt = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "loss_function = DiceLoss(to_onehot_y=True, softmax=True)\n",
    "dice_metric = DiceMetric(include_background=False, reduction=\"mean\")\n",
    "\n",
    "# %% train\n",
    "max_epochs = 1000\n",
    "MeanTeacherEpoch = 50\n",
    "val_interval = 1\n",
    "best_metric = -1\n",
    "best_metric_epoch = -1\n",
    "iter_num = 0\n",
    "epoch_loss_values = []\n",
    "metric_values = []\n",
    "post_pred = Compose([EnsureType(), AsDiscrete(argmax=True, to_onehot=NCLASS)])\n",
    "post_label = Compose([EnsureType(), AsDiscrete(to_onehot=NCLASS)])\n",
    "\n",
    "for epoch in range(max_epochs):\n",
    "    print(\"-\" * 10)\n",
    "    print(f\"epoch {epoch + 1}/{max_epochs}\")\n",
    "    start_time = time()\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    step = 0\n",
    "    for labeled_batch, unlabeled_batch in zip(train_loader, unlabeled_train_loader):\n",
    "        step += 1\n",
    "        labeled_inputs, labels = (\n",
    "            labeled_batch[0].to(device),\n",
    "            labeled_batch[1].to(device),\n",
    "        )\n",
    "        unlabeled_inputs = unlabeled_batch.to(device)\n",
    "        opt.zero_grad()\n",
    "        noise_labeled = torch.clamp(torch.randn_like(\n",
    "                labeled_inputs) * 0.1, -0.2, 0.2)\n",
    "        noise_unlabeled = torch.clamp(torch.randn_like(\n",
    "                unlabeled_inputs) * 0.1, -0.2, 0.2)\n",
    "        noise_labeled_inputs = labeled_inputs + noise_labeled\n",
    "        noise_unlabeled_inputs = unlabeled_inputs + noise_unlabeled\n",
    "        \n",
    "        outputs = model(labeled_inputs)\n",
    "        with torch.no_grad():\n",
    "            soft_out = torch.softmax(outputs, dim=1)\n",
    "            outputs_unlabeled = model(unlabeled_inputs)\n",
    "            soft_unlabeled = torch.softmax(outputs_unlabeled, dim=1)\n",
    "            outputs_aug = ema_model(noise_labeled_inputs)\n",
    "            soft_aug = torch.softmax(outputs_aug, dim=1)\n",
    "            outputs_unlabeled_aug = ema_model(noise_unlabeled_inputs)\n",
    "            soft_unlabeled_aug = torch.softmax(outputs_unlabeled_aug, dim=1)\n",
    "\n",
    "        supervised_loss = loss_function(outputs, labels)\n",
    "        if epoch < MeanTeacherEpoch:\n",
    "                consistency_loss = 0.0\n",
    "        else:\n",
    "            consistency_loss = torch.mean(\n",
    "                (soft_out - soft_aug) ** 2) + \\\n",
    "                               torch.mean(\n",
    "                (soft_unlabeled - soft_unlabeled_aug) ** 2)\n",
    "        consistency_weight = get_current_consistency_weight(iter_num//150)\n",
    "        iter_num += 1\n",
    "        loss = supervised_loss + consistency_weight * consistency_loss\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        update_ema_variables(model, ema_model, 0.99, iter_num)        \n",
    "        epoch_loss += loss.item()\n",
    "        print(\n",
    "            # f\"{step}/{len(unlabeled_train_ds) // unlabeled_train_loader.batch_size}, \"\n",
    "            f\"train_loss: {loss.item():.4f}\")\n",
    "    epoch_loss /= step\n",
    "    epoch_loss_values.append(epoch_loss)\n",
    "\n",
    "    print(f\"epoch {epoch + 1} average loss: {epoch_loss:.4f}\") \n",
    "\n",
    "    if (epoch + 1) % val_interval == 0:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for val_data in val_loader:\n",
    "                val_inputs, val_labels = (\n",
    "                    val_data[0].to(device),\n",
    "                    val_data[1].to(device),\n",
    "                )\n",
    "                val_outputs = model(val_inputs)\n",
    "                # compute metric for current iteration\n",
    "                dice_metric(y_pred=val_outputs, y=val_labels)\n",
    "\n",
    "            # aggregate the final mean dice result\n",
    "            metric = dice_metric.aggregate().item()\n",
    "            print(f\"val dice: {metric}\")\n",
    "            # reset the status for next validation round\n",
    "            dice_metric.reset()\n",
    "\n",
    "        metric_values.append(metric)\n",
    "        if metric > best_metric:\n",
    "            best_metric = metric\n",
    "            best_metric_epoch = epoch + 1\n",
    "            torch.save(model.module.state_dict(), os.path.join(\n",
    "                model_folder, \"best_metric_model.pth\"))\n",
    "            print(\"saved new best metric model\")\n",
    "        print(\n",
    "            f\"current epoch: {epoch + 1} current mean dice: {metric:.4f}\"\n",
    "            f\"\\nbest mean dice: {best_metric:.4f} \"\n",
    "            f\"at epoch: {best_metric_epoch}\"\n",
    "        )\n",
    "    print(f\"epoch time = {time() - start_time}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "69ce82f0454b58f8538f17de03201ff1941f71155f919ebfc63f1bc59487577f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
